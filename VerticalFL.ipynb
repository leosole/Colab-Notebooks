{"cells":[{"cell_type":"code","execution_count":50,"metadata":{"id":"S4z4n9YSfYJ2","executionInfo":{"status":"ok","timestamp":1643930297069,"user_tz":180,"elapsed":400,"user":{"displayName":"Leonardo Solé Rodrigues","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzIlP2fstjRAoHJHfzHACaItDQbGGp0xuhdPuZpgY=s64","userId":"03267990613474009833"}}},"outputs":[],"source":["epochs = 5"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k3kMd1C_iXb6","executionInfo":{"status":"ok","timestamp":1643930299707,"user_tz":180,"elapsed":2252,"user":{"displayName":"Leonardo Solé Rodrigues","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzIlP2fstjRAoHJHfzHACaItDQbGGp0xuhdPuZpgY=s64","userId":"03267990613474009833"}},"outputId":"8a14d2d5-9faa-4728-d2d7-3e08d4972737"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"1NHJbYpBfYJ3"},"source":["# Example - Simple Vertically Partitioned Split Neural Network\n","\n","- <b>Alice</b>\n","    - Has model Segment 1\n","    - Has the handwritten Images\n","- <b>Bob</b>\n","    - Has model Segment 2\n","    - Has the image Labels\n","    \n","Based on [SplitNN - Tutorial 3](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/advanced/split_neural_network/Tutorial%203%20-%20Folded%20Split%20Neural%20Network.ipynb) from Adam J Hall - Twitter: [@AJH4LL](https://twitter.com/AJH4LL) · GitHub:  [@H4LL](https://github.com/H4LL)\n","\n","Authors:\n","- Pavlos Papadopoulos · GitHub:  [@pavlos-p](https://github.com/pavlos-p)\n","- Tom Titcombe · GitHub:  [@TTitcombe](https://github.com/TTitcombe)\n","- Robert Sandmann · GitHub: [@rsandmann](https://github.com/rsandmann)\n"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"k5stMaL-fYJ5","executionInfo":{"status":"ok","timestamp":1643930299708,"user_tz":180,"elapsed":6,"user":{"displayName":"Leonardo Solé Rodrigues","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzIlP2fstjRAoHJHfzHACaItDQbGGp0xuhdPuZpgY=s64","userId":"03267990613474009833"}}},"outputs":[],"source":["class SplitNN:\n","    def __init__(self, models, optimizers):\n","        self.models = models\n","        self.optimizers = optimizers\n","\n","        self.data = []\n","        self.remote_tensors = []\n","\n","    def forward(self, x):\n","        data = []\n","        remote_tensors = []\n","\n","        data.append(self.models[0](x))\n","\n","        if data[-1].location == self.models[1].location:\n","            remote_tensors.append(data[-1].detach().requires_grad_())\n","        else:\n","            remote_tensors.append(\n","                data[-1].detach().move(self.models[1].location).requires_grad_()\n","            )\n","\n","        i = 1\n","        while i < (len(models) - 1):\n","            data.append(self.models[i](remote_tensors[-1]))\n","\n","            if data[-1].location == self.models[i + 1].location:\n","                remote_tensors.append(data[-1].detach().requires_grad_())\n","            else:\n","                remote_tensors.append(\n","                    data[-1].detach().move(self.models[i + 1].location).requires_grad_()\n","                )\n","\n","            i += 1\n","\n","        data.append(self.models[i](remote_tensors[-1]))\n","\n","        self.data = data\n","        self.remote_tensors = remote_tensors\n","\n","        return data[-1]\n","\n","    def backward(self):\n","        for i in range(len(models) - 2, -1, -1):\n","            if self.remote_tensors[i].location == self.data[i].location:\n","                grads = self.remote_tensors[i].grad.copy()\n","            else:\n","                grads = self.remote_tensors[i].grad.copy().move(self.data[i].location)\n","    \n","            self.data[i].backward(grads)\n","\n","    def zero_grads(self):\n","        for opt in self.optimizers:\n","            opt.zero_grad()\n","\n","    def step(self):\n","        for opt in self.optimizers:\n","            opt.step()"]},{"cell_type":"code","source":["!pip install openmined.psi\n","!pip install syft==0.2.9"],"metadata":{"id":"YSh_48PxfgRW"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":54,"metadata":{"id":"JO6ay-oIfYJ6","executionInfo":{"status":"ok","timestamp":1643930306824,"user_tz":180,"elapsed":11,"user":{"displayName":"Leonardo Solé Rodrigues","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzIlP2fstjRAoHJHfzHACaItDQbGGp0xuhdPuZpgY=s64","userId":"03267990613474009833"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e4cc32b2-f125-414e-88ce-737d81aa9ba7"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:root:Torch was already hooked... skipping hooking process\n"]}],"source":["import os\n","# change to path to PyVertical in drive:\n","os.chdir('/content/drive/MyDrive/LEO/UFRJ/IC/vertical/PyVertical')\n","import sys\n","sys.path.append('../')\n","\n","import torch\n","from torchvision import datasets, transforms\n","from torch import nn, optim\n","from torchvision.datasets import MNIST\n","from torchvision.transforms import ToTensor\n","\n","import syft as sy\n","\n","import pandas as pd\n","import numpy as np\n","\n","from torch.utils.data import DataLoader\n","\n","from src.dataloader import VerticalDataLoader\n","from src.psi.util import Client, Server\n","from src.utils import add_ids\n","\n","hook = sy.TorchHook(torch)"]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Dataset\n","from uuid import uuid4\n","from typing import List\n","\n","class FraudDataset(Dataset):\n","  def __init__(self, file_out, sc):\n","    # x = file_out.iloc[1:284807, 1:30].values\n","    # y = file_out.iloc[1:284807, 30].values\n","    x = file_out.iloc[:, 1:30].values\n","    y = file_out.iloc[:, 30].values\n","\n","    x_transform = sc.transform(x)\n","\n","    self.data = torch.tensor(x_transform, dtype=torch.float32)\n","    self.targets = torch.tensor(y, dtype=torch.float32)\n","\n","    self.ids = np.array([uuid4() for _ in range(len(file_out))])\n","\n","  def __len__(self):\n","    if self.data is not None:\n","      return self.data.size(0)\n","    else:\n","      return len(self.targets)\n","\n","  def __getitem__(self, idx):\n","    return self.data[idx], self.targets[idx]\n","\n","  def get_ids(self) -> List[str]:\n","    return [str(id_) for id_ in self.ids]\n","\n","  def sort_by_ids(self):\n","        ids = self.get_ids()\n","        sorted_idxs = np.argsort(ids)\n","\n","        if self.data is not None:\n","            self.data = self.data[sorted_idxs]\n","\n","        if self.targets is not None:\n","            self.targets = self.targets[sorted_idxs]\n","\n","        self.ids = self.ids[sorted_idxs]"],"metadata":{"id":"7aaMoRTVFzjg","executionInfo":{"status":"ok","timestamp":1643930306824,"user_tz":180,"elapsed":6,"user":{"displayName":"Leonardo Solé Rodrigues","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzIlP2fstjRAoHJHfzHACaItDQbGGp0xuhdPuZpgY=s64","userId":"03267990613474009833"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","execution_count":56,"metadata":{"id":"VbdpV6sZfYJ8","executionInfo":{"status":"ok","timestamp":1643930309039,"user_tz":180,"elapsed":2220,"user":{"displayName":"Leonardo Solé Rodrigues","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzIlP2fstjRAoHJHfzHACaItDQbGGp0xuhdPuZpgY=s64","userId":"03267990613474009833"}}},"outputs":[],"source":["os.chdir('/content/drive/MyDrive/Colab Notebooks/data')\n","file_out = pd.read_csv(\"creditcard.csv\")\n","x_train = file_out.iloc[1:10000, :]\n","x_sc = x_train.iloc[:,1:30].values\n","sc = StandardScaler()\n","sc.fit(x_sc)\n","x_test = file_out.iloc[10000:15000, :]\n","dataset = FraudDataset(x_train, sc)\n","testset = FraudDataset(x_test, sc)\n","\n","# Batch data\n","dataloader = VerticalDataLoader(dataset, batch_size=128) # partition_dataset uses by default \"remove_data=True, keep_order=False\"\n"]},{"cell_type":"markdown","metadata":{"id":"sIvlo2vjfYJ9"},"source":["## Implement PSI and order the datasets accordingly"]},{"cell_type":"code","execution_count":57,"metadata":{"id":"GpLQwXO0fYJ-","executionInfo":{"status":"ok","timestamp":1643930316750,"user_tz":180,"elapsed":7715,"user":{"displayName":"Leonardo Solé Rodrigues","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzIlP2fstjRAoHJHfzHACaItDQbGGp0xuhdPuZpgY=s64","userId":"03267990613474009833"}}},"outputs":[],"source":["# Compute private set intersection\n","client_items = dataloader.dataloader1.dataset.get_ids()\n","server_items = dataloader.dataloader2.dataset.get_ids()\n","\n","client = Client(client_items)\n","server = Server(server_items)\n","\n","setup, response = server.process_request(client.request, len(client_items))\n","intersection = client.compute_intersection(setup, response)\n","\n","# Order data\n","dataloader.drop_non_intersecting(intersection)\n","dataloader.sort_by_ids()"]},{"cell_type":"code","execution_count":58,"metadata":{"id":"BLRq6pxTfYKA","executionInfo":{"status":"ok","timestamp":1643930316753,"user_tz":180,"elapsed":10,"user":{"displayName":"Leonardo Solé Rodrigues","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzIlP2fstjRAoHJHfzHACaItDQbGGp0xuhdPuZpgY=s64","userId":"03267990613474009833"}}},"outputs":[],"source":["torch.manual_seed(0)\n","\n","# Define our model segments\n","\n","input_size = 29\n","hidden_sizes = [128, 128]\n","output_size = 1\n","\n","models = [\n","    nn.Sequential(\n","        nn.Linear(input_size, hidden_sizes[0]),\n","        nn.ReLU(),\n","        nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n","        nn.ReLU(),\n","    ),\n","    nn.Sequential(nn.Linear(hidden_sizes[1], output_size), nn.Sigmoid()),\n","]\n","\n","# Create optimisers for each segment and link to them\n","optimizers = [\n","    optim.SGD(model.parameters(), lr=0.03,)\n","    for model in models\n","]\n","\n","# create some workers\n","alice = sy.VirtualWorker(hook, id=\"alice\")\n","bob = sy.VirtualWorker(hook, id=\"bob\")\n","\n","# Send Model Segments to model locations\n","model_locations = [alice, bob]\n","for model, location in zip(models, model_locations):\n","    model.send(location)\n","\n","#Instantiate a SpliNN class with our distributed segments and their respective optimizers\n","splitNN = SplitNN(models, optimizers)"]},{"cell_type":"code","execution_count":59,"metadata":{"id":"HGxP328QfYKA","executionInfo":{"status":"ok","timestamp":1643930316753,"user_tz":180,"elapsed":9,"user":{"displayName":"Leonardo Solé Rodrigues","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzIlP2fstjRAoHJHfzHACaItDQbGGp0xuhdPuZpgY=s64","userId":"03267990613474009833"}}},"outputs":[],"source":["def train(x, target, splitNN):\n","    \n","    #1) Zero our grads\n","    splitNN.zero_grads()\n","    \n","    #2) Make a prediction\n","    pred = splitNN.forward(x)\n","\n","    #3) Figure out how much we missed by\n","    criterion = nn.BCELoss()\n","    loss = criterion(pred, target)\n","    \n","    #4) Backprop the loss on the end layer\n","    loss.backward()\n","    \n","    #5) Feed Gradients backward through the nework\n","    splitNN.backward()\n","    \n","    #6) Change the weights\n","    splitNN.step()\n","    \n","    return loss, pred"]},{"cell_type":"code","execution_count":60,"metadata":{"id":"BStLKj1kfYKB","executionInfo":{"status":"ok","timestamp":1643931925760,"user_tz":180,"elapsed":1609014,"user":{"displayName":"Leonardo Solé Rodrigues","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzIlP2fstjRAoHJHfzHACaItDQbGGp0xuhdPuZpgY=s64","userId":"03267990613474009833"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3ba8053f-7f0b-43b4-e652-24e5d5d31f34"},"outputs":[{"output_type":"stream","name":"stdout","text":[" epoch 0: 100.0% | tp: 31.0, tn: 9956, fp: 5, fn: 7.0\n"," epoch 0: training loss: 1.191 - f1 score: 0.838\n"," epoch 1: 100.0% | tp: 36.0, tn: 9959, fp: 2, fn: 2.0\n"," epoch 1: training loss: 0.204 - f1 score: 0.947\n"," epoch 2: 100.0% | tp: 36.0, tn: 9960, fp: 1, fn: 2.0\n"," epoch 2: training loss: 0.198 - f1 score: 0.960\n"," epoch 3: 100.0% | tp: 36.0, tn: 9960, fp: 1, fn: 2.0\n"," epoch 3: training loss: 0.146 - f1 score: 0.960\n"," epoch 4: 100.0% | tp: 36.0, tn: 9960, fp: 1, fn: 2.0\n"," epoch 4: training loss: 0.177 - f1 score: 0.960\n"]}],"source":["for i in range(epochs):\n","    running_loss = 0\n","    correct_preds = 0\n","    total_preds = 0\n","    tp, fp, tn, fn = 0, 0, 0, 0\n","    j = 0\n","    for (data, label) in zip(dataloader.dataloader1.dataset.data, dataloader.dataloader2.dataset.targets):\n","        # Train a model\n","        data = data.send(models[0].location)\n","        # data = data.view(data.shape[0], -1)\n","        label = label.send(models[-1].location)\n","        label = label.view(1)\n","\n","        # Call model\n","        loss, preds = train(data, label, splitNN)\n","        pred = round(float(preds.get()[0]))\n","        lab = float(label.get()[0])\n","        # Collect statistics\n","        tp += (pred and lab)\n","        fp += (pred and not lab)\n","        tn += (not pred and not lab)\n","        fn += (not pred and lab)\n","        percent = j / dataloader.dataloader2.dataset.targets.shape[0] * 100\n","        j += 1\n","        print(f'\\r epoch {i}: {percent:.1f}% | tp: {tp}, tn: {tn}, fp: {fp}, fn: {fn}', end='')\n","        running_loss += loss.get()\n","    f1_score = tp / (tp + (fp + fn)/2)\n","    print(f\" | training loss: {running_loss/len(dataloader):.3f} | f1 score: {f1_score:.3f}\")"]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","testloaderC = DataLoader(testset, batch_size=64, shuffle=True)\n","\n","testloader = VerticalDataLoader(testset, batch_size=128)\n","client_items = testloader.dataloader1.dataset.get_ids()\n","server_items = testloader.dataloader2.dataset.get_ids()\n","\n","client = Client(client_items)\n","server = Server(server_items)\n","\n","setup, response = server.process_request(client.request, len(client_items))\n","intersection = client.compute_intersection(setup, response)\n","\n","# Order data\n","testloader.drop_non_intersecting(intersection)\n","testloader.sort_by_ids()"],"metadata":{"id":"Qiu97o2PJd2C","executionInfo":{"status":"ok","timestamp":1643931928615,"user_tz":180,"elapsed":2860,"user":{"displayName":"Leonardo Solé Rodrigues","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzIlP2fstjRAoHJHfzHACaItDQbGGp0xuhdPuZpgY=s64","userId":"03267990613474009833"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["tp, fp, tn, fn = 0, 0, 0, 0\n","for sample, label in zip(testloader.dataloader1.dataset.data, testloader.dataloader2.dataset.targets):\n","    sample = sample.send(models[0].location)\n","    # data = data.view(data.shape[0], -1)\n","    label = label.send(models[-1].location)\n","    label = label.view(1)\n","    # Call model\n","    splitNN.zero_grads()\n","    pred = splitNN.forward(sample)\n","    pred = round(float(pred.get()[0]))\n","    lab = float(label.get()[0])\n","    # Collect statistics\n","    tp += (pred and lab)\n","    fp += (pred and not lab)\n","    tn += (not pred and not lab)\n","    fn += (not pred and lab)\n","    print(f'\\r tp: {tp}, fp: {fp}, tn: {tn}, fn: {fn}', end='')\n","f1_score = tp / (tp + (fp + fn)/2)\n","print(f'\\n test f1 score: {f1_score:.3f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4AIhOBrcKlev","executionInfo":{"status":"ok","timestamp":1643932031126,"user_tz":180,"elapsed":102516,"user":{"displayName":"Leonardo Solé Rodrigues","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzIlP2fstjRAoHJHfzHACaItDQbGGp0xuhdPuZpgY=s64","userId":"03267990613474009833"}},"outputId":"7920156d-fdae-4dfd-bbf6-1caa76646b0a"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":[" tp: 18.0, fp: 22, tn: 4955, fn: 5.0\n"," test f1 score: 0.571\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.11"},"colab":{"name":"VerticalFL.ipynb","provenance":[{"file_id":"1JlgMucimKcdX6s0IfSqLFhrncHE41MJM","timestamp":1643060215154}],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}