{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CÃ³pia de TFF_for_model_and_update_compression_(full_copy).ipynb","provenance":[{"file_id":"1KGmAwEUj4TwWiYMR_uk1ZA34nF8femjT","timestamp":1611175895343}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"exFeYM4KWlz9"},"source":["##### Copyright 2020 The TensorFlow Authors."]},{"cell_type":"code","metadata":{"cellView":"form","id":"Oj6X6JHoWtVs"},"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d5DZ2c-xfa9m"},"source":["# TFF for Federated Learning Research: Model and Update Compression\n","\n","**NOTE**: This colab has been verified to work with the [latest released version](https://github.com/tensorflow/federated#compatibility) of the `tensorflow_federated` pip package, but the Tensorflow Federated project is still in pre-release development and may not work on `master`.\n","\n","In this tutorial, we use the [EMNIST](https://www.tensorflow.org/federated/api_docs/python/tff/simulation/datasets/emnist) dataset to demonstrate how to enable lossy compression algorithms to reduce communication cost in the Federated Averaging algorithm using the `tff.learning.build_federated_averaging_process` API and the [tensor_encoding](http://jakubkonecny.com/files/tensor_encoding.pdf) API. For more details on the Federated Averaging algorithm, see the paper [Communication-Efficient Learning of Deep Networks from Decentralized Data](https://arxiv.org/abs/1602.05629)."]},{"cell_type":"markdown","metadata":{"id":"qrPTFv7ngz-P"},"source":["## Before we start\n","\n","Before we start, please run the following to make sure that your environment is\n","correctly setup. If you don't see a greeting, please refer to the\n","[Installation](../install.md) guide for instructions."]},{"cell_type":"code","metadata":{"id":"X_JnSqDxlw5T"},"source":["#@title Install tensorflow_federated and load TensorBoard\n","#@test {\"skip\": true}\n","!pip install --quiet --upgrade tensorflow_federated\n","!pip install --quiet --upgrade nest_asyncio\n","\n","%load_ext tensorboard\n","\n","import nest_asyncio\n","nest_asyncio.apply()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ctxIBpYIl846"},"source":["import functools\n","import logging\n","import time\n","import warnings\n","\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_federated as tff\n","\n","from tensorflow_model_optimization.python.core.internal import tensor_encoding as te\n","\n","# Ignore warning messages from TensorFlow and Python.\n","tf.get_logger().setLevel(logging.ERROR)\n","warnings.simplefilter(\"ignore\")\n","\n","np.random.seed(0)\n","tff.federated_computation(lambda: 'Hello, world!')()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"30Pln72ihL-z"},"source":["## Preparing the input data\n","In this section we load and preprocess the EMNIST dataset similiar to the process in [Federated Learning for Image Classification](https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification#preparing_the_input_data) tutorial. However there is a small difference in the `batch_format_fn` since the model in that tutorial expects an input with shape (-1, 784) and the model in this tutorial expects an input with shape (28, 28, 1). You should modify the `batch_format_fn` function corresponding to the input shape of your model.\n"]},{"cell_type":"code","metadata":{"id":"oTP2Dndbl2Oe"},"source":["NUM_CLIENTS = 10\n","NUM_EPOCHS = 1\n","BATCH_SIZE = 20\n","PREFETCH_BUFFER = 10\n","# This value only applies to EMNIST dataset, consider choosing appropriate\n","# values if switching to other datasets.\n","SHUFFLE_BUFFER = 418\n","\n","emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data(\n","    only_digits=True)\n","\n","def preprocess_fn(dataset):\n","  \"\"\"Preprocessing function for the EMNIST training dataset.\"\"\"\n","  def batch_format_fn(element):\n","    \"\"\"Reshape a batch `pixels` and return the features as an `OrderedDict`.\"\"\"\n","    return (tf.expand_dims(element['pixels'], axis=-1), element['label'])\n","\n","  return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(\n","      BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)\n","\n","emnist_train = emnist_train.preprocess(preprocess_fn)\n","emnist_test = emnist_test.preprocess(preprocess_fn)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XUQA55yjhTGh"},"source":["## Defining a model\n","\n","Here we define a keras model based on the orginial FedAvg CNN, and then wrap the keras model in an instance of [tff.learning.Model](https://www.tensorflow.org/federated/api_docs/python/tff/learning/Model) so that it can be consumed by TFF."]},{"cell_type":"markdown","metadata":{"id":"MnHpAtO6tcIf"},"source":["### Define a keras model\n","\n","Note that in [Federated Learning for Image Classification](https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification#creating_a_model_with_keras) tutorial, the model is a simple one-layer neural network where in this tutorial, we define a slightly more complicated model."]},{"cell_type":"code","metadata":{"id":"KSHYy4VPybqH"},"source":["def create_original_fedavg_cnn_model(only_digits=True):\n","  \"\"\"The CNN model used in https://arxiv.org/abs/1602.05629.\"\"\"\n","  data_format = 'channels_last'\n","\n","  max_pool = functools.partial(\n","      tf.keras.layers.MaxPooling2D,\n","      pool_size=(2, 2),\n","      padding='same',\n","      data_format=data_format)\n","  conv2d = functools.partial(\n","      tf.keras.layers.Conv2D,\n","      kernel_size=5,\n","      padding='same',\n","      data_format=data_format,\n","      activation=tf.nn.relu)\n","\n","  model = tf.keras.models.Sequential([\n","      tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),\n","      conv2d(filters=32),\n","      max_pool(),\n","      conv2d(filters=64),\n","      max_pool(),\n","      tf.keras.layers.Flatten(),\n","      tf.keras.layers.Dense(512, activation=tf.nn.relu),\n","      tf.keras.layers.Dense(10 if only_digits else 62),\n","      tf.keras.layers.Softmax(),\n","  ])\n","\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"829rO5jfyq_G"},"source":["We can use [tf.keras.Model.summary()](https://www.tensorflow.org/api_docs/python/tf/keras/Model#summary) to see the network architecture. "]},{"cell_type":"code","metadata":{"id":"O3UgvgSdyhUk"},"source":["print(create_original_fedavg_cnn_model().summary())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Iw1rj1izH9Y"},"source":["### Define a TFF model function\n","\n","Wrap the keras model in an instance of `tff.learning.Model`, note that we'll need a **function** which produces a model instead of simply a model directly. In addition, the function **cannot** just capture a pre-constructed model, it must create the model in the context that it is called. The reason is that TFF is designed to go to devices, and needs control over when resources are constructed so that they can be captured and packaged up."]},{"cell_type":"code","metadata":{"id":"f2dLONjFnE2E"},"source":["# Gets the type information of the input data. TFF is a strongly typed\n","# functional programming framework, and needs type information about inputs to \n","# the model.\n","example_dataset = emnist_train.create_tf_dataset_for_client(\n","    emnist_train.client_ids[0])\n","input_spec = example_dataset.element_spec\n","\n","\n","def tff_model_fn():\n","  keras_model = create_original_fedavg_cnn_model()\n","  return tff.learning.from_keras_model(\n","      keras_model=keras_model,\n","      input_spec=input_spec,\n","      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ipfUaPLEhYYj"},"source":["## Run training and evaluation with metrics visualization\n","\n","Now we are ready to construct a Federated Averaging algorithm and train and evaluate the defined model on EMNIST dataset."]},{"cell_type":"markdown","metadata":{"id":"wVlPVFp91Xz3"},"source":["### Build a training process\n","First we need to build a Federated Averaging algorithm using the [tff.learning.build_federated_averaging_process](https://www.tensorflow.org/federated/api_docs/python/tff/learning/build_federated_averaging_process) API."]},{"cell_type":"code","metadata":{"id":"SAsGGkL9nHEl"},"source":["federated_averaging = tff.learning.build_federated_averaging_process(\n","    model_fn=tff_model_fn,\n","    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n","    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rtnADdU91z_1"},"source":["### Build a evaluation process\n","\n","Then, we build a Federated evaluation process using the [tff.learning.build_federated_evaluation](https://www.tensorflow.org/federated/api_docs/python/tff/learning/build_federated_evaluation) API."]},{"cell_type":"code","metadata":{"id":"JPvav70W2PXW"},"source":["evaluation_process = tff.learning.build_federated_evaluation(tff_model_fn)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mn1FAPQ32FcV"},"source":["### Run training and evaluation process\n","\n","Before the actual run, let's define some utility functions."]},{"cell_type":"code","metadata":{"id":"t5n9fXsGOO6-","cellView":"form"},"source":["#@title Load utility functions\n","def format_size(size):\n","  \"\"\"A helper function for creating a human-readable size.\"\"\"\n","  size = float(size)\n","  for unit in ['B','KiB','MiB','GiB']:\n","    if size < 1024.0:\n","      return \"{size:3.2f}{unit}\".format(size=size, unit=unit)\n","    size /= 1024.0\n","  return \"{size:.2f}{unit}\".format(size=size, unit='TiB')\n","\n","def make_federated_data(client_data, client_ids):\n","  return [\n","      client_data.create_tf_dataset_for_client(x)\n","      for x in client_ids\n","  ]\n","\n","def set_sizing_environment():\n","  \"\"\"Creates an environment that contains sizing information.\"\"\"\n","  # Creates a sizing executor factory to output communication cost\n","  # after the training finishes. Note that sizing executor only provides an\n","  # estimate (not exact) of communication cost, and doesn't capture cases like\n","  # compression of over-the-wire representations. However, it's perfect for\n","  # demonstrating the effect of compression in this tutorial.\n","  sizing_factory = tff.framework.sizing_executor_factory()\n","\n","  # TFF has a modular runtime you can configure yourself for various\n","  # environments and purposes, and this example just shows how to configure one\n","  # part of it to report the size of things.\n","  context = tff.framework.ExecutionContext(executor_fn=sizing_factory)\n","  tff.framework.set_default_context(context)\n","\n","  return sizing_factory"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qkdsZMJN2fwe"},"source":["Now let's define a function to run the Federated Averaging algorithm. The execution of a Federated Learning algorithm from the perspective of TFF looks like this:\n","\n","1. Initialize the algorithm and get the inital server state. The server state contains necessary information to perform the algorithm. Recall, since TFF is functional, that this state includes both any optimizer state the algorithm uses (e.g. momentum terms) as well as the model parameters themselves--these will be passed as arguments and returned as results from TFF computations.\n","2. Execute the algorithm round by round. In each round, a new server state will be returned as the result of each client training the model on its data. Typically in one round:\n","    1. Server broadcast the model to all the participating clients.\n","    2. Each client perform work based on the model and its own data.\n","    3. Server aggregates all the model to produce a sever state which contains a new model.\n","\n","Training metrics are written to the Tensorboard directory for displaying during the training and evaluation process."]},{"cell_type":"code","metadata":{"id":"jvH6qIgynI8S"},"source":["def run_experiment(federated_averaging_process, num_rounds, num_clients_per_round, summary_writer):\n","  \"\"\"Runs the federated averaging process and output metrics.\"\"\"\n","  # Create a environment to get communication cost.\n","  environment = set_sizing_environment()\n","\n","  # Initialize the Federated Averaging algorithm to get the initial server state.\n","  state = federated_averaging_process.initialize()\n","\n","  with summary_writer.as_default():\n","    for round_num in range(num_rounds):\n","      round_start_time = time.time()\n","      # Sample the clients participated in this round.\n","      sampled_clients = np.random.choice(\n","          emnist_train.client_ids,\n","          size=num_clients_per_round,\n","          replace=False)\n","      # Create a list of `tf.Dataset` instances from the data of sampled clients.\n","      sampled_train_data = make_federated_data(emnist_train, sampled_clients)\n","      # Round one round of the algorithm based on the server state and client data\n","      # and output the new state and metrics.\n","      state, metrics = federated_averaging_process.next(state, sampled_train_data)\n","\n","      # For more about size_info, please see https://www.tensorflow.org/federated/api_docs/python/tff/framework/SizeInfo\n","      size_info = environment.get_size_info()\n","      broadcasted_bits = size_info.broadcast_bits[-1]\n","      aggregated_bits = size_info.aggregate_bits[-1]\n","\n","      print(f'Train: round {round_num:2d}, metrics={metrics}, '\n","            f'broadcasted_bits={format_size(broadcasted_bits)}, '\n","            f'aggregated_bits={format_size(aggregated_bits)}, '\n","            f'time={time.time() - round_start_time:.2f}s')\n","\n","      sampled_clients = np.random.choice(\n","        emnist_test.client_ids,\n","        size=num_clients_per_round,\n","        replace=False)\n","      federated_test_data = make_federated_data(emnist_test, sampled_clients)\n","      test_metrics = evaluation_process(state.model, federated_test_data)\n","      print('Eval: test_metrics={}'.format(test_metrics))\n","\n","      # Add test metrics to Tensorboard.\n","      for name, value in test_metrics.items():\n","        tf.summary.scalar('test_' + name, value, step=round_num)\n","\n","      # Add training metrics to Tensorboard.\n","      for name, value in metrics['train'].items():\n","        tf.summary.scalar(name, value, step=round_num)\n","\n","      # Add broadcasted and aggregated data size to Tensorboard.\n","      tf.summary.scalar('cumulative_broadcasted_bits', broadcasted_bits, step=round_num)\n","      tf.summary.scalar('cumulative_aggregated_bits', aggregated_bits, step=round_num)\n","      summary_writer.flush()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ydsry9k3282U"},"source":["Start TensorBoard display the training and evaluation metrics. It can take a few seconds for the data to load while the new data generated from training. Except for Loss and Accuracy, we also output the amount of broadcasted and aggregated data. Broadcasted data refers to tensors the server pushes to each client while aggregated data refers to tensors each client returns to the server."]},{"cell_type":"code","metadata":{"id":"Xw78G3uq2Ygi"},"source":["# Clean the log directory to avoid conflicts.\n","!rm -R /tmp/logs/scalars/*\n","\n","logdir = \"/tmp/logs/scalars/original/\"\n","%tensorboard --logdir /tmp/logs/scalars/ --port=0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BlAwmQwT5ZLr"},"source":["Run!"]},{"cell_type":"code","metadata":{"id":"xp3o3QcBlqY_"},"source":["# Set up the log directory and writer for Tensorboard.\n","summary_writer = tf.summary.create_file_writer(logdir)\n","\n","run_experiment(federated_averaging_process=federated_averaging, num_rounds=10,\n","               num_clients_per_round=10, summary_writer=summary_writer)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ubLmAiXl3T99"},"source":["In the above cell, we run for 10 rounds just to test everything out, but for an interesting experiment we recommend running for at least 1500 rounds, which should produce a model with over 98% accuracy; test accuracy will continue to improve up to 2000 rounds, with accuracy plateauing around 99%. Running for 1500 rounds on a CPU Colab backend should take about 2.8 hours. If you fine-tune the hyperparameters, you can get even better convergence speed."]},{"cell_type":"markdown","metadata":{"id":"rY5tWN_5ht6-"},"source":["## Build a custom broadcast and aggregate function\n","\n","Now let's implement function to use lossy compression algorithms on broadcasted data and aggregated data using the [tensor_encoding](http://jakubkonecny.com/files/tensor_encoding.pdf) API."]},{"cell_type":"markdown","metadata":{"id":"ZCsINdXcij5e"},"source":["### tensor_encoding API\n","\n","tensor_encoding API is a general TensorFlow tool for invertible, potentially lossy, transformations.\n","\n","Research surface API:\n","* `te.encoders.identity`\n","* `te.encoders.uniform_quantization`\n","\n","Platform surface API:\n","* `te.core.SimpleEncoder`: An encoder for broadcast process in Federated Learning.\n","* `te.core.GatherEncoder`: An encoder for aggregation process of Federated Learning.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eu7vgVlfmvAv"},"source":["**How to build an encoder to perform uniform quantization?**\n","\n","Uniform quantization is basically a simple rounding process, in which each tensor value is rounded to the nearest value from a set of possible quantization levels ([min, max] separated into 2^8 buckets).\n","\n","An exmaple of 2-bit uniform quantization of x1 in `X=[x1, x2, x3, ..., xn]` (Note that `Xmin = min(X)`, `Xman = max(X)`):\n","\n","```\n"," |--------0-|-------0---------0---------|\n","Xmin        x1                         Xmax\n","```\n","After uniform quantization:\n","\n","```\n"," |--------*---------0---------0---------|\n","Xmin      x1                           Xmax\n","```"]},{"cell_type":"code","metadata":{"id":"VGfyU570mgpq"},"source":["te.encoders.uniform_quantization(bits=8)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DMOfDZ94qBWn"},"source":["**How to build an encoder for TFF?**"]},{"cell_type":"code","metadata":{"id":"c5DKO_r3p9U2"},"source":["spec = tf.TensorSpec(tf.TensorShape([10, 10]), tf.float32)\n","\n","# A te.core.SimpleEncoder for broadcast process.\n","te.encoders.as_simple_encoder(te.encoders.uniform_quantization(bits=8), spec)\n","\n","# A te.core.GatherEncoder for aggregation process.\n","te.encoders.as_gather_encoder(te.encoders.uniform_quantization(bits=8), spec)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ltIITTayiMar"},"source":["**How to build a federated averaging algorithm with compression?**\n","\n","First, we define two functions:\n","* `broadcast_encoder_fn` which creates an instance of [te.core.SimpleEncoder](https://github.com/tensorflow/model-optimization/blob/master/tensorflow_model_optimization/python/core/internal/tensor_encoding/core/simple_encoder.py#L30) to encode tensors or variables in server to client communication (Broadcast data).\n","* `mean_encoder_fn` which creates an instance of [te.core.GatherEncoder](https://github.com/tensorflow/model-optimization/blob/master/tensorflow_model_optimization/python/core/internal/tensor_encoding/core/gather_encoder.py#L30) to encode tensors or variables in client to server communicaiton (Aggregation data).\n","\n","It is important to note that we do not apply a compression method to the entire model at once. Instead, we decide how (and whether) to compress each variable of the model independently. The reason is that generally, small variables such as biases are more sensitive to inaccuracy, and being relatively small, the potential communication savings are also relatively small. Hence we do not compress small variables by default. In this example, we apply uniform quantization to 8 bits (256 buckets) to every variable with more than 10000 elements, and only apply identity to other variables."]},{"cell_type":"code","metadata":{"id":"lkRHkZTTnKn2"},"source":["def broadcast_encoder_fn(value):\n","  \"\"\"Function for building encoded broadcast.\"\"\"\n","  spec = tf.TensorSpec(value.shape, value.dtype)\n","  if value.shape.num_elements() > 10000:\n","    return te.encoders.as_simple_encoder(\n","        te.encoders.uniform_quantization(bits=8), spec)\n","  else:\n","    return te.encoders.as_simple_encoder(te.encoders.identity(), spec)\n","\n","\n","def mean_encoder_fn(value):\n","  \"\"\"Function for building encoded mean.\"\"\"\n","  spec = tf.TensorSpec(value.shape, value.dtype)\n","  if value.shape.num_elements() > 10000:\n","    return te.encoders.as_gather_encoder(\n","        te.encoders.uniform_quantization(bits=8), spec)\n","  else:\n","    return te.encoders.as_gather_encoder(te.encoders.identity(), spec)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WvTZrkwuOSBl"},"source":["**Iterative process**\n","\n","A composition of the following processes:\n","* A **broadcast process** which sends model to each clients.\n","* A **client process** which does something using the model and client data.\n","* A **aggregation process** which sends the whatever produced in clients back to server.\n","* A **server process** which does something using the aggregated models."]},{"cell_type":"markdown","metadata":{"id":"82iYUklQKP2e"},"source":["TFF provides APIs to convert the encoder function into a format that `tff.learning.build_federated_averaging_process` API can consume. By using the `tff.learning.framework.build_encoded_broadcast_from_model` and `tff.learning.framework.build_encoded_mean_from_model`, we can create two functions that can be passed into `broadcast_process` and `aggregation_process` agruments of `tff.learning.build_federated_averaging_process` to create a Federated Averaging algorithms with a lossy compression algorithm."]},{"cell_type":"code","metadata":{"id":"aqD61hqAGZiW"},"source":["encoded_broadcast_process = (\n","    tff.learning.framework.build_encoded_broadcast_process_from_model(\n","        tff_model_fn, broadcast_encoder_fn))\n","encoded_mean_process = (\n","    tff.learning.framework.build_encoded_mean_process_from_model(\n","    tff_model_fn, mean_encoder_fn))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mf-7bBy9s9tf"},"source":["Build the Federated Averaging algorithmm again with the compression algorithms."]},{"cell_type":"code","metadata":{"id":"BvjLmxh7rQQf"},"source":["federated_averaging_with_compression = tff.learning.build_federated_averaging_process(\n","    tff_model_fn,\n","    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n","    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0),\n","    broadcast_process=encoded_broadcast_process,\n","    aggregation_process=encoded_mean_process)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v3-ADI0hjTqH"},"source":["## Training the model again\n","\n","Now let's run the new Federated Averaging algorithm."]},{"cell_type":"code","metadata":{"id":"0KM_THYdn1yH"},"source":["logdir_for_compression = \"/tmp/logs/scalars/compression/\"\n","summary_writer_for_compression = tf.summary.create_file_writer(\n","    logdir_for_compression)\n","\n","run_experiment(federated_averaging_process=federated_averaging_with_compression,\n","               num_rounds=10,\n","               num_clients_per_round=10,\n","               summary_writer=summary_writer_for_compression)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sE8Bnjel8TIA"},"source":["Please navigate back to the tensorboard above to compare the training metrics between two runs.\n","\n","As you can see in Tensorboard, there is a significant reduction between the `orginial` and `compression` curves in the `broadcasted_bits` and `aggregated_bits` plots while in the `loss` and `sparse_categorical_accuracy` plot the two curves are pretty similiar.\n","\n","In conclusion, we implemented a compression algorithm that can achieve similar performance as the orignial Federated Averaging algorithm while the comminucation cost is significently reduced."]},{"cell_type":"markdown","metadata":{"id":"Jaz9_9H7NUMW"},"source":["## Exercises\n","\n","To implement a custom compression algorithm and apply it to the training loop,\n","you can:\n","\n","1.  Implement a new compression algorithm as a subclass of\n","    [`EncodingStageInterface`](https://github.com/tensorflow/model-optimization/blob/master/tensorflow_model_optimization/python/core/internal/tensor_encoding/core/encoding_stage.py#L75)\n","    or its more general variant,\n","    [`AdaptiveEncodingStageInterface`](https://github.com/tensorflow/model-optimization/blob/master/tensorflow_model_optimization/python/core/internal/tensor_encoding/core/encoding_stage.py#L274)\n","    following\n","    [this example](https://github.com/tensorflow/federated/blob/master/tensorflow_federated/python/research/compression/sparsity.py).\n","1.  Construct your new\n","    [`Encoder`](https://github.com/tensorflow/model-optimization/blob/master/tensorflow_model_optimization/python/core/internal/tensor_encoding/core/core_encoder.py#L38)\n","    and specialize it for\n","    [model broadcast](https://github.com/tensorflow/federated/blob/master/tensorflow_federated/python/research/compression/run_experiment.py#L95)\n","    or\n","    [model update averaging](https://github.com/tensorflow/federated/blob/master/tensorflow_federated/python/research/compression/run_experiment.py#L121).\n","1.  Use those objects to build the entire\n","    [training computation](https://github.com/tensorflow/federated/blob/master/tensorflow_federated/python/research/compression/run_experiment.py#L204).\n","\n","Potentially valuable open research questions include: non-uniform quantization, lossless compression such as huffman coding, and mechanisms for adapting compression based on the information from previous training rounds.\n","\n","Recommended reading materials:\n","* [Expanding the Reach of Federated Learning by Reducing Client Resource Requirements](https://research.google/pubs/pub47774/)\n","* [Federated Learning: Strategies for Improving Communication Efficiency](https://research.google/pubs/pub45648/)\n","* _Section 3.5 Communication and Compression_ in [Advanced and Open Problems in Federated Learning](https://arxiv.org/abs/1912.04977)"]}]}